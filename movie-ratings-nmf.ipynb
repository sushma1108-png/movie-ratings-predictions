{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1872300,"sourceType":"datasetVersion","datasetId":1114664}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:01.981003Z","iopub.execute_input":"2025-04-17T04:56:01.982049Z","iopub.status.idle":"2025-04-17T04:56:02.313443Z","shell.execute_reply.started":"2025-04-17T04:56:01.982017Z","shell.execute_reply":"2025-04-17T04:56:02.312669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-1m-dataset/users.dat\n/kaggle/input/movielens-1m-dataset/ratings.dat\n/kaggle/input/movielens-1m-dataset/README\n/kaggle/input/movielens-1m-dataset/movies.dat\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Limitations of sk-learn's NMF library","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import NMF\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:11.528784Z","iopub.execute_input":"2025-04-17T04:56:11.529432Z","iopub.status.idle":"2025-04-17T04:56:12.503888Z","shell.execute_reply.started":"2025-04-17T04:56:11.529398Z","shell.execute_reply":"2025-04-17T04:56:12.503187Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define column names for each file\nmovies_columns = ['movie_id', 'title', 'genres']\nusers_columns = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\nratings_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n\nmovies_data = pd.read_csv('/kaggle/input/movielens-1m-dataset/movies.dat',sep='::', encoding='ISO-8859-1', \n                          header=None, names=movies_columns, engine='python')\nusers_data = pd.read_csv('/kaggle/input/movielens-1m-dataset/users.dat',sep='::',encoding='ISO-8859-1', \n                         header=None, names=users_columns, engine='python')\nratings_data = pd.read_csv('/kaggle/input/movielens-1m-dataset/ratings.dat',sep='::',encoding='ISO-8859-1', \n                           header=None, names=ratings_columns,engine='python')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:14.401794Z","iopub.execute_input":"2025-04-17T04:56:14.402635Z","iopub.status.idle":"2025-04-17T04:56:19.466099Z","shell.execute_reply.started":"2025-04-17T04:56:14.402607Z","shell.execute_reply":"2025-04-17T04:56:19.465285Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(\"Movies data shape:\", movies_data.shape)\nprint(\"Users data shape:\", users_data.shape)\nprint(\"Ratings data shape:\", ratings_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:19.467336Z","iopub.execute_input":"2025-04-17T04:56:19.467628Z","iopub.status.idle":"2025-04-17T04:56:19.472611Z","shell.execute_reply.started":"2025-04-17T04:56:19.467598Z","shell.execute_reply":"2025-04-17T04:56:19.471782Z"}},"outputs":[{"name":"stdout","text":"Movies data shape: (3883, 3)\nUsers data shape: (6040, 5)\nRatings data shape: (1000209, 4)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create user-item ratings matrix\nn_users = ratings_data['user_id'].max() + 1  # User IDs start at 1\nn_items = ratings_data['movie_id'].max() + 1  # Movie IDs start at 1\nratings_matrix = np.zeros((n_users, n_items))\n\n# Fill the ratings matrix\nfor row in ratings_data.itertuples():\n    ratings_matrix[row.user_id, row.movie_id] = row.rating\n\n# Split into train and test sets (80% train, 20% test)\ntrain_indices = ratings_data.sample(frac=0.8, random_state=42).index\ntest_indices = ratings_data.drop(train_indices).index\n\ntrain_matrix = np.zeros((n_users, n_items))\ntest_matrix = np.zeros((n_users, n_items))\n\n# Fill train and test matrices\nfor idx in train_indices:\n    row = ratings_data.loc[idx]\n    train_matrix[int(row['user_id']), int(row['movie_id'])] = row['rating']\n\nfor idx in test_indices:\n    row = ratings_data.loc[idx]\n    test_matrix[int(row['user_id']), int(row['movie_id'])] = row['rating']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:19.473399Z","iopub.execute_input":"2025-04-17T04:56:19.473629Z","iopub.status.idle":"2025-04-17T04:56:48.465804Z","shell.execute_reply.started":"2025-04-17T04:56:19.473610Z","shell.execute_reply":"2025-04-17T04:56:48.465055Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Apply NMF with tuned parameters\nn_components = 15\nmodel = NMF(n_components=n_components, \n            init='nndsvd', \n            random_state=42, \n            max_iter=2000,  # Increased from 500\n            tol=1e-3,       # Relaxed tolerance\n            alpha_W=0.01,   # Regularization for W\n            alpha_H=0.01,   # Regularization for H\n            l1_ratio=0.5)   # Mix of L1 and L2 regularization\n\nW = model.fit_transform(train_matrix)  # User latent factors\nH = model.components_  # Item latent factors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:35.536552Z","iopub.execute_input":"2025-04-17T04:57:35.537209Z","iopub.status.idle":"2025-04-17T04:58:03.144611Z","shell.execute_reply.started":"2025-04-17T04:57:35.537181Z","shell.execute_reply":"2025-04-17T04:58:03.143770Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Predict ratings\npredicted_matrix = np.dot(W, H)\n\n# Clip predictions to valid rating range (1–5)\npredicted_matrix = np.clip(predicted_matrix, 1, 5)\n\n# Extract test set ratings and predictions\ntest_indices = np.where(test_matrix > 0)\nactual_ratings = test_matrix[test_indices]\npredicted_ratings = predicted_matrix[test_indices]\n\n# Compute RMSE\nrmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\nprint(f\"NMF RMSE: {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:58:35.543370Z","iopub.execute_input":"2025-04-17T04:58:35.544067Z","iopub.status.idle":"2025-04-17T04:58:35.908625Z","shell.execute_reply.started":"2025-04-17T04:58:35.544037Z","shell.execute_reply":"2025-04-17T04:58:35.907831Z"}},"outputs":[{"name":"stdout","text":"NMF RMSE: 2.5138\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Results of matrix factorization:\n\nThe RMSE of 2.5138 from sklearn’s Non-Negative Matrix Factorization (NMF) on the MovieLens 1M dataset is significantly higher than the RMSE values from the simple baseline and similarity-based methods which I computed (ranging from 0.981 to 1.258). This indicates that NMF performed poorly compared to these methods\n\nWhy non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods?\n1. Improper handling of missing ratings:\n  * NMF treats missing ratings as actual zero ratings, biasing predictions toward low values and leading to large errors for actual ratings (1–5), where as in the earlier scenarios it would ignore the missing ratings & handling it well.\n2. Sparsity in the data:\n*  we have 6,040 users × 3,883 movies, if everyone gives the rating to all movies then we would be having 18Million+ rating but here we only have 1Million dataset & there is more sparse data matrix, this would be computationally inefficient, However, baseline & similarity methods are uneffected by the sparsity.\n3. Lack of other feature data:\n*  this is just ratings matrix & this wouldn't use genres & location information & making in inefficient in the rating prediction but in the previous methods, they have used all the features well.\n\nHow to fix this better?\n1. Handle the missing ratings well, instead of taking them as 0, use the average of the movies.\n2. Better handling of sparsity, the sparse data matrix will slow the convergence & decimates the factorization. filter the users or movies to make is dense matrix, which does better factorization & predicts well.\n3. Incorporate the missing lables information, which further enhances the prediction for the movie ratings.","metadata":{}}]}